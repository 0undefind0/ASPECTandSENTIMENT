{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pickle\n",
    "import tensorflow_hub as hub\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import json\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# getAspectDescription(text: string) => [{aspect: string, description: string}]\n",
    "\n",
    "def getAspects(text):\n",
    "    aspects = []\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        target = []\n",
    "        for token in sent:\n",
    "            if (token.dep_ == 'nsubj' or token.dep_ == 'dobj') and token.pos_ == 'NOUN' and token.ent_type_ == '':\n",
    "                target.append(token.text)\n",
    "        if target:\n",
    "            aspects.extend(target)\n",
    "    return aspects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(texts):\n",
    "    model = pickle.load(open('SentimentModel/bigdata2modelNB.pkl', 'rb'))\n",
    "\n",
    "    aspect_sentiments = []\n",
    "    for text in texts:\n",
    "        \"\"\"\n",
    "        function getSentiment(raw_text: string) -> (output: string, prediction: (polarity, subjectivity))\n",
    "\n",
    "        This function takes in a string of raw text and performs sentiment analysis to determine whether the text is positive or negative. It returns a tuple consisting of the sentiment label and the positive probability of the prediction.\n",
    "\n",
    "        Args:\n",
    "            raw_text (str): The raw text to analyze.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple consisting of the sentiment label and the positive probability of the prediction.\n",
    "\n",
    "        Example:\n",
    "            >>> raw_text = \"This product is amazing! I love it so much.\"\n",
    "            >>> getSentiment(raw_text)\n",
    "            ('Positive', 0.00819811, 0.99180189))\n",
    "        \"\"\"\n",
    "\n",
    "        # Instantiate PorterStemmer\n",
    "        p_stemmer = PorterStemmer()\n",
    "\n",
    "        # Remove HTML\n",
    "        review_text = BeautifulSoup(text).get_text()\n",
    "\n",
    "        # Remove non-letters\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "\n",
    "        # Convert words to lower case and split each word up\n",
    "        words = letters_only.lower().split()\n",
    "\n",
    "        # Convert stopwords to a set\n",
    "        stops = set(stopwords.words('english'))\n",
    "\n",
    "        # Adding on stopwords that were appearing frequently in both positive and negative reviews\n",
    "        stops.update(['app','shopee','shoppee','item','items','seller','sellers','bad'])\n",
    "\n",
    "        # Remove stopwords\n",
    "        meaningful_words = [w for w in words if w not in stops]\n",
    "\n",
    "        # Stem words\n",
    "        meaningful_words = [p_stemmer.stem(w) for w in meaningful_words]\n",
    "\n",
    "        # Join words back into one string, with a space in between each word\n",
    "        final_text = pd.Series(\" \".join(meaningful_words))\n",
    "\n",
    "        # Generate predictions\n",
    "        pred = model.predict(final_text)[0]\n",
    "        positive_prob = model.predict_proba([pd.Series.to_string(final_text)])\n",
    "\n",
    "        pd.options.display.max_colwidth = None\n",
    "        pd.options.display.max_rows = None\n",
    "        print(\"TEXT: \", pd.Series.to_string(final_text))\n",
    "\n",
    "        if pred == 1:\n",
    "            output = \"Negative\"\n",
    "        else:\n",
    "            output = \"Postive\"\n",
    "    \n",
    "        aspect_sentiments.append([text, output, positive_prob])\n",
    "\n",
    "    return aspect_sentiments\n",
    "    #return output, positive_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47806649, 0.52193351]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open('SentimentModel/bigdata2modelNB.pkl', 'rb'))\n",
    "model.predict_proba(['batteri charg quickli support wireless charg ad conveni'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:  0    screen high resolut sharp clear imag\n",
      "TEXT:  0    batteri charg quickli support wireless charg ad conveni\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['The screen has a high resolution for sharp and clear images.',\n",
       "  'Postive',\n",
       "  array([[0.50733507, 0.49266493]])],\n",
       " ['The battery charges quickly and supports wireless charging for added convenience.',\n",
       "  'Negative',\n",
       "  array([[0.47806649, 0.52193351]])]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentiment(['The screen has a high resolution for sharp and clear images.', 'The battery charges quickly and supports wireless charging for added convenience.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupAspects(aspect_list):\n",
    "    # Load pre-trained Word2Vec model\n",
    "    word_model = KeyedVectors.load_word2vec_format('Aspect-Extraction\\GoogleNews-vectors-negative300.bin', \n",
    "                                                binary=True, limit=500000)\n",
    "\n",
    "    # Convert aspects to word vectors\n",
    "    aspect_vectors = [word_model[aspect] for aspect in aspect_list]\n",
    "\n",
    "    # Cluster word vectors using k-means\n",
    "    kmeans = KMeans(n_clusters=7)\n",
    "    kmeans.fit(aspect_vectors)\n",
    "    clusters = kmeans.predict(aspect_vectors)\n",
    "\n",
    "    # Find representative label for each cluster\n",
    "    labels = []\n",
    "    grouped_aspects = {}\n",
    "    for i in range(kmeans.n_clusters):\n",
    "        cluster_vectors = [aspect_vectors[j] for j in range(len(aspect_vectors)) if clusters[j] == i]\n",
    "        centroid = np.mean(cluster_vectors, axis=0)\n",
    "        distances = cdist([centroid], cluster_vectors, metric='cosine')\n",
    "        closest_index = np.argmin(distances)\n",
    "        label = aspect_list[np.where(clusters == i)[0][closest_index]]\n",
    "        labels.append(label)\n",
    "        grouped_aspects[label] = [aspect_list[j] for j in range(len(aspect_list)) if clusters[j] == i]\n",
    "\n",
    "    return grouped_aspects\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def group_sentiments(aspect_sentiments, grouped_aspects, embedder):\n",
    "    result = {}\n",
    "    for label, aspects in grouped_aspects.items():\n",
    "        result[label] = []\n",
    "        aspect_embeddings = embedder(aspects)\n",
    "        for text, output, positive_prob in aspect_sentiments:\n",
    "            text_embedding = embedder([text])[0]\n",
    "            similarities = cosine_similarity(text_embedding.reshape(1,-1), aspect_embeddings)\n",
    "            if max(similarities[0]) > 0.289:\n",
    "                result[label].append((text, output, positive_prob))\n",
    "    return result\n",
    "\n",
    "def embedder(texts):\n",
    "    return embed(texts).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The device has a large and vibrant display that makes everything look great.\",\n",
    "    \"Its camera takes stunning photos with vivid colors and sharp details.\",\n",
    "    \"The battery life is impressive and lasts all day with heavy use.\",\n",
    "    \"The size is perfect for one-handed use and fits comfortably in a pocket.\",\n",
    "    \"The screen is responsive and easy to navigate with intuitive gestures.\",\n",
    "    \"The pictures captured by the camera are of professional quality.\",\n",
    "    \"The life of the device is extended by its durable construction and regular software updates.\",\n",
    "    \"The colors on the display are accurate and true to life.\",\n",
    "    \"The performance is smooth and fast, even when running multiple apps at once.\",\n",
    "    \"The design is sleek and modern, with a premium feel.\",\n",
    "    \"The display is protected by scratch-resistant glass for added durability.\",\n",
    "    \"The camera has advanced features such as portrait mode and night mode for stunning photos in any lighting condition.\",\n",
    "    \"The battery charges quickly and supports wireless charging for added convenience.\",\n",
    "    \"The size of the device is perfect for watching videos and playing games.\",\n",
    "    \"The screen has a high resolution for sharp and clear images.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\steam\\Desktop\\MachineLearningProjects\\COMBINEDAspect-BasedSentimentAnalysisUsingSpacyTextBlob\\combinedenv\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'camera': ['camera', 'camera'], 'display': ['display', 'life', 'colors', 'performance', 'design', 'features', 'charging'], 'apps': ['device', 'apps'], 'size': ['size', 'size'], 'screen': ['screen', 'screen'], 'photos': ['photos', 'pictures', 'videos'], 'resolution': ['resolution']}\n"
     ]
    }
   ],
   "source": [
    "new_text = ' '.join(sentences)\n",
    "aspect_list = getAspects(new_text)\n",
    "group_aspects = groupAspects(aspect_list)\n",
    "print(group_aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58097448, 0.41902552]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open('SentimentModel/bigdata2modelNB.pkl', 'rb'))\n",
    "model.predict_proba(['The battery charges quickly and supports wireless charging for added convenience.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen has a high resolution for sharp and clear images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.794, 'pos': 0.206, 'compound': 0.3818}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Instantiate the sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Print a negative review in the training set\n",
    "print('The screen has a high resolution for sharp and clear images.')\n",
    "\n",
    "# VADER's polarity scores for the negative review\n",
    "sia.polarity_scores('The screen has a high resolution for sharp and clear images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The screen has a high resolution for sharp and clear images.',\n",
       "  'Postive',\n",
       "  array([[0.50733507, 0.49266493]])],\n",
       " ['The battery charges quickly and supports wireless charging for added convenience.',\n",
       "  'Negative',\n",
       "  array([[0.366848, 0.633152]])]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentiment(['The screen has a high resolution for sharp and clear images.', 'The battery charges quickly and supports wireless charging for added convenience.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04116534  0.03324282 -0.03086034 ...  0.03107716  0.01527658\n",
      "   0.03016139]\n",
      " [-0.02420701  0.04582939  0.01411261 ...  0.01786607 -0.02259821\n",
      "  -0.02726042]\n",
      " [-0.03270246 -0.01961841 -0.00080166 ...  0.02664647  0.00477472\n",
      "   0.02659776]\n",
      " ...\n",
      " [ 0.02352348 -0.0133323  -0.00828289 ...  0.04613282 -0.07519539\n",
      "   0.05771908]\n",
      " [-0.0283571  -0.03624243 -0.03549223 ... -0.00527885 -0.00512973\n",
      "   0.01658252]\n",
      " [-0.01287641  0.02537684  0.00207782 ...  0.03250806  0.00827598\n",
      "  -0.01529129]]\n",
      "camera:\n",
      "  ('Its camera takes stunning photos with vivid colors and sharp details.', 'Postive', array([[0.58097448, 0.41902552]]))\n",
      "  ('The pictures captured by the camera are of professional quality.', 'Postive', array([[0.64088682, 0.35911318]]))\n",
      "display:\n",
      "  ('The device has a large and vibrant display that makes everything look great.', 'Postive', array([[0.68497571, 0.31502429]]))\n",
      "  ('The performance is smooth and fast, even when running multiple apps at once.', 'Postive', array([[0.67877738, 0.32122262]]))\n",
      "  ('The battery charges quickly and supports wireless charging for added convenience.', 'Negative', array([[0.366848, 0.633152]]))\n",
      "apps:\n",
      "size:\n",
      "  ('The size is perfect for one-handed use and fits comfortably in a pocket.', 'Postive', array([[0.82068528, 0.17931472]]))\n",
      "screen:\n",
      "  ('The device has a large and vibrant display that makes everything look great.', 'Postive', array([[0.68497571, 0.31502429]]))\n",
      "  ('The screen has a high resolution for sharp and clear images.', 'Postive', array([[0.50733507, 0.49266493]]))\n",
      "photos:\n",
      "resolution:\n",
      "  ('The screen has a high resolution for sharp and clear images.', 'Postive', array([[0.50733507, 0.49266493]]))\n"
     ]
    }
   ],
   "source": [
    "sentiments = getSentiment(sentences)\n",
    "print(embedder(sentences))\n",
    "group_sentences = group_sentiments(sentiments, group_aspects, embedder)\n",
    "for label, sentences in group_sentences.items():\n",
    "    print(f\"{label}:\")\n",
    "    for sentence in sentences:\n",
    "        print(f\"  {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'camera': ['camera', 'camera'], 'display': ['display', 'life', 'colors', 'performance', 'design', 'features', 'charging'], 'apps': ['device', 'apps'], 'size': ['size', 'size'], 'screen': ['screen', 'screen'], 'photos': ['photos', 'pictures', 'videos'], 'resolution': ['resolution']}\n",
      "camera\n",
      "display\n",
      "apps\n",
      "size\n",
      "screen\n",
      "photos\n",
      "resolution\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m group_sentences:\n\u001b[0;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(item)\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m sentiment \u001b[39min\u001b[39;00m getSentiment(sentences):\n\u001b[0;32m      5\u001b[0m     positive_prob \u001b[39m=\u001b[39m sentiment[\u001b[39m2\u001b[39m]\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(positive_prob))\n",
      "Cell \u001b[1;32mIn[15], line 58\u001b[0m, in \u001b[0;36mgetSentiment\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     55\u001b[0m p_stemmer \u001b[39m=\u001b[39m PorterStemmer()\n\u001b[0;32m     57\u001b[0m \u001b[39m# Remove HTML\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m review_text \u001b[39m=\u001b[39m BeautifulSoup(text)\u001b[39m.\u001b[39mget_text()\n\u001b[0;32m     60\u001b[0m \u001b[39m# Remove non-letters\u001b[39;00m\n\u001b[0;32m     61\u001b[0m letters_only \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m\"\u001b[39m\u001b[39m[^a-zA-Z]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, review_text)\n",
      "File \u001b[1;32md:\\Users\\steam\\Desktop\\MachineLearningProjects\\COMBINEDAspect-BasedSentimentAnalysisUsingSpacyTextBlob\\combinedenv\\Lib\\site-packages\\bs4\\__init__.py:328\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m rejections \u001b[39m=\u001b[39m []\n\u001b[0;32m    327\u001b[0m success \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m \u001b[39mfor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmarkup, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_encoding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeclared_html_encoding,\n\u001b[0;32m    329\u001b[0m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontains_replacement_characters) \u001b[39min\u001b[39;00m (\n\u001b[0;32m    330\u001b[0m      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mprepare_markup(\n\u001b[0;32m    331\u001b[0m          markup, from_encoding, exclude_encodings\u001b[39m=\u001b[39mexclude_encodings)):\n\u001b[0;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[0;32m    333\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\steam\\Desktop\\MachineLearningProjects\\COMBINEDAspect-BasedSentimentAnalysisUsingSpacyTextBlob\\combinedenv\\Lib\\site-packages\\bs4\\builder\\_htmlparser.py:361\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.prepare_markup\u001b[1;34m(self, markup, user_specified_encoding, document_declared_encoding, exclude_encodings)\u001b[0m\n\u001b[0;32m    358\u001b[0m user_encodings \u001b[39m=\u001b[39m [document_declared_encoding]\n\u001b[0;32m    360\u001b[0m try_encodings \u001b[39m=\u001b[39m [user_specified_encoding, document_declared_encoding]\n\u001b[1;32m--> 361\u001b[0m dammit \u001b[39m=\u001b[39m UnicodeDammit(\n\u001b[0;32m    362\u001b[0m     markup,\n\u001b[0;32m    363\u001b[0m     known_definite_encodings\u001b[39m=\u001b[39;49mknown_definite_encodings,\n\u001b[0;32m    364\u001b[0m     user_encodings\u001b[39m=\u001b[39;49muser_encodings,\n\u001b[0;32m    365\u001b[0m     is_html\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    366\u001b[0m     exclude_encodings\u001b[39m=\u001b[39;49mexclude_encodings\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[39myield\u001b[39;00m (dammit\u001b[39m.\u001b[39mmarkup, dammit\u001b[39m.\u001b[39moriginal_encoding,\n\u001b[0;32m    369\u001b[0m        dammit\u001b[39m.\u001b[39mdeclared_html_encoding,\n\u001b[0;32m    370\u001b[0m        dammit\u001b[39m.\u001b[39mcontains_replacement_characters)\n",
      "File \u001b[1;32md:\\Users\\steam\\Desktop\\MachineLearningProjects\\COMBINEDAspect-BasedSentimentAnalysisUsingSpacyTextBlob\\combinedenv\\Lib\\site-packages\\bs4\\dammit.py:601\u001b[0m, in \u001b[0;36mUnicodeDammit.__init__\u001b[1;34m(self, markup, known_definite_encodings, smart_quotes_to, is_html, exclude_encodings, user_encodings, override_encodings)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmarkup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mmarkup\n\u001b[0;32m    600\u001b[0m u \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 601\u001b[0m \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mencodings:\n\u001b[0;32m    602\u001b[0m     markup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mmarkup\n\u001b[0;32m    603\u001b[0m     u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_from(encoding)\n",
      "File \u001b[1;32md:\\Users\\steam\\Desktop\\MachineLearningProjects\\COMBINEDAspect-BasedSentimentAnalysisUsingSpacyTextBlob\\combinedenv\\Lib\\site-packages\\bs4\\dammit.py:434\u001b[0m, in \u001b[0;36mEncodingDetector.encodings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39m# Look within the document for an XML or HTML encoding\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[39m# declaration.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeclared_encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeclared_encoding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_declared_encoding(\n\u001b[0;32m    435\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_html)\n\u001b[0;32m    436\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_usable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeclared_encoding, tried):\n\u001b[0;32m    437\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeclared_encoding\n",
      "File \u001b[1;32md:\\Users\\steam\\Desktop\\MachineLearningProjects\\COMBINEDAspect-BasedSentimentAnalysisUsingSpacyTextBlob\\combinedenv\\Lib\\site-packages\\bs4\\dammit.py:511\u001b[0m, in \u001b[0;36mEncodingDetector.find_declared_encoding\u001b[1;34m(cls, markup, is_html, search_entire_document)\u001b[0m\n\u001b[0;32m    509\u001b[0m html_re \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mhtml\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    510\u001b[0m declared_encoding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 511\u001b[0m declared_encoding_match \u001b[39m=\u001b[39m xml_re\u001b[39m.\u001b[39;49msearch(markup, endpos\u001b[39m=\u001b[39;49mxml_endpos)\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m declared_encoding_match \u001b[39mand\u001b[39;00m is_html:\n\u001b[0;32m    513\u001b[0m     declared_encoding_match \u001b[39m=\u001b[39m html_re\u001b[39m.\u001b[39msearch(markup, endpos\u001b[39m=\u001b[39mhtml_endpos)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object, got 'tuple'"
     ]
    }
   ],
   "source": [
    "print(group_aspects)\n",
    "for item in group_sentences:\n",
    "    print(item)\n",
    "for sentiment in getSentiment(sentences):\n",
    "    positive_prob = sentiment[2]\n",
    "    print(type(positive_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "combinedenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
